# Azure-Data-Engineering-Project-Series
## Project #1 :- Handle Error Rows in Data Factory Mapping Data Flows
In this project i have built an pipeline in Azure Data Factory which is going to extract multiple employee csv files from the ADLS Gen2 and used Data flow transformations to seperate good and bad data from the each csv file.
Finally i stored the good and bad rows seperatley in the seperate table in the Azure SQL Database.
## pipeline
![image](https://github.com/user-attachments/assets/0c04ea37-b158-4a02-8da6-2995fb90df94)
## Dataflow
![image](https://github.com/user-attachments/assets/abe78c2b-bd1e-4904-8038-4762713177ad)
## pipeline execution
![image](https://github.com/user-attachments/assets/6cc21fa2-0bec-422f-8be3-3a41dbae00b4)
## Input datasets
![image](https://github.com/user-attachments/assets/e798fffc-bd4a-4dd6-ae1e-03ec909cd366)
## Output filtered rows
### Good rows
![image](https://github.com/user-attachments/assets/8e6331d5-da86-4fc4-8ff9-c4cbdcf81bde)
### Bad rows
![image](https://github.com/user-attachments/assets/4502825f-c74f-48db-854c-48494139153b)
## Project #2 :- Copy Multiple Files with Prefix employee
## Project #3 :- Delete files older than 30 days
